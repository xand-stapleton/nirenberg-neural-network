{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "149b65c6",
   "metadata": {},
   "source": [
    "### 3D Metric Embedding Visualisation\n",
    "\n",
    "This notebook creates a faithful 3D embedding of the learned 2D metric tensor on the sphere. The approach:\n",
    "\n",
    "1. **Create a unified sphere mesh** from both stereographic patches (North and South hemispheres)\n",
    "   - Structured disc meshes are generated for each patch and mapped to 3D via stereographic projection\n",
    "   - A convex hull triangulation joins the two hemispheres into a single mesh\n",
    "\n",
    "2. **Compute metric-weighted edge lengths** using the learned metric tensor $g_{ij}$\n",
    "   - For same-patch edges: $\\ell = \\int_0^1 \\sqrt{(\\vec{v})^T g(\\vec{x}(t)) \\vec{v}} \\, dt$ where $\\vec{v} = \\vec{p}_2 - \\vec{p}_1$\n",
    "   - For cross-patch edges: spherical geodesic distance is used as an approximation\n",
    "\n",
    "3. **Build geodesic distance matrix** via shortest paths on the mesh graph\n",
    "\n",
    "4. **Multi-Dimensional Scaling (MDS)** embeds the distance matrix into 3D Euclidean space\n",
    "   - Procrustes alignment orients the embedding to match the reference sphere\n",
    "\n",
    "5. **Compute scalar curvature** $R$ at each vertex using the learned metric\n",
    "\n",
    "6. **Visualise** the resulting surface:\n",
    "   - Plot 1: 3D mesh embedding (optionally side-by-side with reference sphere)\n",
    "   - Plot 2: Embedding coloured by scalar curvature $R$\n",
    "\n",
    "**Output:** Shows how the learned metric deforms sphere geometry. Figures are saved to `visualisations/` with filenames including `R_kind` and (for spherical harmonics) the `ms` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ec463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and relevant functions\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "from scipy.spatial import Delaunay, ConvexHull\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "from scipy.sparse.csgraph import shortest_path\n",
    "from sklearn.manifold import MDS\n",
    "import warnings\n",
    "\n",
    "# Import relevant functions for new model format\n",
    "from data.dataset import list_saved_models\n",
    "from data.prescribers import build_prescriber\n",
    "from network.global_conformal_model import GlobalConformalModel\n",
    "from geometry.ball import patch_xy_to_xyz, xyz_to_patch_xy\n",
    "\n",
    "# Output the list of saved models (to select which to import with in the following cell)\n",
    "saved_models = list_saved_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3033c8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which checkpoint folder(s) to use (by index or name)\n",
    "model_index = 0  # Change this to select a different run folder\n",
    "selected_folder = saved_models[model_index]\n",
    "# Define checkpoints_dir if not already defined\n",
    "checkpoints_dir = \"checkpoints\"  # Default directory for checkpoints\n",
    "selected_folder_path = os.path.join(checkpoints_dir, selected_folder)\n",
    "\n",
    "# Epoch numbers to visualize (list for multiple, single value, or \"all\")\n",
    "# Examples:\n",
    "#   epoch_numbers = [50, 75, 94]  # specific epochs\n",
    "#   epoch_numbers = 94            # single epoch\n",
    "#   epoch_numbers = \"all\"         # all available epochs\n",
    "#   epoch_numbers = \"final\"       # only final_model.keras\n",
    "epoch_numbers = \"all\"\n",
    "\n",
    "# Find all epoch checkpoint .keras files in the selected folder\n",
    "all_model_files = glob.glob(os.path.join(selected_folder_path, \"model_epoch*.keras\"))\n",
    "def extract_epoch_num(filename):\n",
    "    m = re.search(r\"model_epoch(\\d+)\\.keras\", filename)\n",
    "    return int(m.group(1)) if m else None\n",
    "model_files = [(extract_epoch_num(f), f) for f in all_model_files]\n",
    "model_files = [(e, f) for e, f in model_files if e is not None]\n",
    "model_files.sort()\n",
    "\n",
    "# Check for final_model.keras\n",
    "final_model_path = os.path.join(selected_folder_path, \"final_model.keras\")\n",
    "has_final_model = os.path.exists(final_model_path)\n",
    "\n",
    "# Filter by epoch_numbers\n",
    "if epoch_numbers == \"final\":\n",
    "    # Only load final model\n",
    "    if has_final_model:\n",
    "        selected_models = [(\"final\", final_model_path)]\n",
    "    else:\n",
    "        print(\"Warning: final_model.keras not found, falling back to latest epoch model\")\n",
    "        selected_models = [model_files[-1]] if model_files else []\n",
    "elif epoch_numbers == \"all\":\n",
    "    selected_models = model_files\n",
    "    # Optionally add final model if it exists and no epoch checkpoints found\n",
    "    if has_final_model and not model_files:\n",
    "        selected_models = [(\"final\", final_model_path)]\n",
    "elif isinstance(epoch_numbers, int):\n",
    "    selected_models = [mf for mf in model_files if mf[0] == epoch_numbers]\n",
    "elif isinstance(epoch_numbers, (list, tuple)):\n",
    "    selected_models = [mf for mf in model_files if mf[0] in epoch_numbers]\n",
    "else:\n",
    "    selected_models = []\n",
    "\n",
    "print(f\"Selected models (epochs): {[e for e, _ in selected_models]}\")\n",
    "\n",
    "# Load all selected models\n",
    "custom_objects = {'GlobalConformalModel': GlobalConformalModel}\n",
    "loaded_models = []\n",
    "for epoch, model_path in selected_models:\n",
    "    loaded_models.append(tf.keras.models.load_model(model_path, custom_objects=custom_objects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd1029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for mesh creation\n",
    "\n",
    "def create_disc_mesh(n_radial=20, n_angular=40, radius=0.95):\n",
    "    \"\"\"Create a structured mesh on the disc with concentric rings.\"\"\"\n",
    "    vertices = [(0.0, 0.0)]\n",
    "    for i in range(1, n_radial + 1):\n",
    "        r = radius * (i / n_radial)\n",
    "        n_pts = max(8, int(n_angular * r / radius))\n",
    "        for j in range(n_pts):\n",
    "            theta = 2 * np.pi * j / n_pts\n",
    "            vertices.append((r * np.cos(theta), r * np.sin(theta)))\n",
    "    vertices = np.array(vertices)\n",
    "    return vertices, Delaunay(vertices).simplices\n",
    "\n",
    "def disc_to_sphere(disc_coords, patch_idx=0):\n",
    "    \"\"\"Map 2D disc coords to 3D sphere coords via patch_xy_to_xyz.\"\"\"\n",
    "    disc_tf = tf.convert_to_tensor(disc_coords, dtype=tf.float64)\n",
    "    return patch_xy_to_xyz(disc_tf, patch_idx=patch_idx).numpy()\n",
    "\n",
    "def create_full_sphere_mesh(n_radial=15, n_angular=32, overlap_radius=0.85):\n",
    "    \"\"\"\n",
    "    Create a unified mesh covering the full sphere from both patches.\n",
    "    Returns vertices_3d, faces, disc coords for each patch, and index arrays.\n",
    "    \"\"\"\n",
    "    vertices_disc_north, _ = create_disc_mesh(n_radial, n_angular, radius=overlap_radius)\n",
    "    vertices_3d_north = disc_to_sphere(vertices_disc_north, patch_idx=0)\n",
    "    \n",
    "    vertices_disc_south, _ = create_disc_mesh(n_radial, n_angular, radius=overlap_radius)\n",
    "    vertices_3d_south = disc_to_sphere(vertices_disc_south, patch_idx=1)\n",
    "    \n",
    "    n_north = len(vertices_3d_north)\n",
    "    n_south = len(vertices_3d_south)\n",
    "    \n",
    "    vertices_3d = np.vstack([vertices_3d_north, vertices_3d_south])\n",
    "    north_indices = np.arange(n_north)\n",
    "    south_indices = np.arange(n_north, n_north + n_south)\n",
    "    \n",
    "    # Triangulate on sphere via convex hull\n",
    "    hull = ConvexHull(vertices_3d)\n",
    "    faces = hull.simplices\n",
    "    \n",
    "    return vertices_3d, faces, vertices_disc_north, vertices_disc_south, north_indices, south_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325f0d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for distance computation\n",
    "\n",
    "def get_disc_coords_for_vertex(vertices_disc_north, vertices_disc_south, \n",
    "                                north_indices, vertex_idx):\n",
    "    \"\"\"Get disc coordinates and patch index for a vertex.\"\"\"\n",
    "    if vertex_idx in north_indices:\n",
    "        return vertices_disc_north[vertex_idx], 0\n",
    "    else:\n",
    "        return vertices_disc_south[vertex_idx - len(north_indices)], 1\n",
    "\n",
    "def slerp(p0, p1, t):\n",
    "    \"\"\"Spherical linear interpolation between two 3D points on the unit sphere.\"\"\"\n",
    "    omega = np.arccos(np.clip(np.dot(p0, p1), -1.0, 1.0))\n",
    "    if omega < 1e-10:\n",
    "        return p0  # Points are very close\n",
    "    return (np.sin((1-t)*omega) * p0 + np.sin(t*omega) * p1) / np.sin(omega)\n",
    "\n",
    "def compute_edge_length(v1_idx, v2_idx, vertices_3d,\n",
    "                        vertices_disc_north, vertices_disc_south,\n",
    "                        north_indices, south_indices,\n",
    "                        loaded_model, n_subdivisions=5):\n",
    "    \"\"\"Compute metric-weighted edge length using model prediction.\"\"\"\n",
    "    disc1, patch1 = get_disc_coords_for_vertex(vertices_disc_north, vertices_disc_south, north_indices, v1_idx)\n",
    "    disc2, patch2 = get_disc_coords_for_vertex(vertices_disc_north, vertices_disc_south, north_indices, v2_idx)\n",
    "\n",
    "    if patch1 == patch2:\n",
    "        # Same patch: compute metric-weighted distance directly\n",
    "        direction = np.asarray(disc2 - disc1, dtype=np.float64).ravel()\n",
    "        # Handle degenerate case of identical vertices\n",
    "        if np.linalg.norm(direction) < 1e-14:\n",
    "            return 0.0\n",
    "        \n",
    "        t_vals = np.linspace(0, 1, n_subdivisions + 1)\n",
    "        points = np.array([disc1 + t * direction for t in t_vals])  # (N, 2)\n",
    "        \n",
    "        # Model expects (batch, num_patches, 2) where batch = N points\n",
    "        # Stack same coords for both patches: (N, 2, 2)\n",
    "        points_both_patches = np.stack([points, points], axis=1)  # (N, 2, 2)\n",
    "        points_tf = tf.convert_to_tensor(points_both_patches, dtype=tf.float64)\n",
    "        \n",
    "        batch_dict = {loaded_model.patch_coords_key: points_tf}\n",
    "        output = loaded_model(batch_dict, training=False)\n",
    "        # Output shape: (batch, num_patches, 2, 2) = (N, 2, 2, 2)\n",
    "        g = output[loaded_model.conformal_metric_key][:, patch1, :, :].numpy()  # shape (N, 2, 2)\n",
    "        \n",
    "        # Compute metric-weighted norm at each point along the line\n",
    "        integrand = []\n",
    "        for gg in g:\n",
    "            # gg is (2, 2)\n",
    "            # Compute v^T @ g @ v = direction.T @ gg @ direction\n",
    "            gv = gg @ direction  # (2,2) @ (2,) -> (2,)\n",
    "            val = direction @ gv  # (2,) @ (2,) -> scalar\n",
    "            val_scalar = float(val)\n",
    "            integrand.append(np.sqrt(max(val_scalar, 1e-12)))\n",
    "        \n",
    "        # Manual trapezoidal rule\n",
    "        integrand = np.array(integrand)\n",
    "        dt = np.diff(t_vals)\n",
    "        avg = 0.5 * (integrand[:-1] + integrand[1:])\n",
    "        return float(np.sum(dt * avg))\n",
    "    else:\n",
    "        # Cross-patch: interpolate along great circle on sphere, evaluate metric in appropriate patch\n",
    "        xyz1 = vertices_3d[v1_idx]\n",
    "        xyz2 = vertices_3d[v2_idx]\n",
    "        \n",
    "        # Normalize to ensure they're on unit sphere\n",
    "        xyz1 = xyz1 / np.linalg.norm(xyz1)\n",
    "        xyz2 = xyz2 / np.linalg.norm(xyz2)\n",
    "        \n",
    "        # Use spherical linear interpolation (great circle path)\n",
    "        t_vals = np.linspace(0, 1, n_subdivisions + 1)\n",
    "        xyz_points = np.array([slerp(xyz1, xyz2, t) for t in t_vals])\n",
    "        \n",
    "        # For each segment, determine which patch to use and compute metric-weighted length\n",
    "        total_length = 0.0\n",
    "        for i in range(len(t_vals) - 1):\n",
    "            t_mid = 0.5 * (t_vals[i] + t_vals[i+1])\n",
    "            xyz_mid = slerp(xyz1, xyz2, t_mid)\n",
    "            \n",
    "            # Choose patch based on which pole is closer (z > 0 -> north, z < 0 -> south)\n",
    "            if xyz_mid[2] >= 0:\n",
    "                use_patch = 0\n",
    "            else:\n",
    "                use_patch = 1\n",
    "            \n",
    "            # Convert segment endpoints to patch coordinates\n",
    "            disc_start = xyz_to_patch_xy(tf.constant([xyz_points[i]], dtype=tf.float64), \n",
    "                                         patch_idx=use_patch).numpy()[0]\n",
    "            disc_end = xyz_to_patch_xy(tf.constant([xyz_points[i+1]], dtype=tf.float64), \n",
    "                                       patch_idx=use_patch).numpy()[0]\n",
    "            \n",
    "            # Direction in patch coordinates\n",
    "            direction = np.asarray(disc_end - disc_start, dtype=np.float64).ravel()\n",
    "            \n",
    "            if np.linalg.norm(direction) < 1e-14:\n",
    "                continue\n",
    "            \n",
    "            # Evaluate metric at midpoint\n",
    "            disc_mid = xyz_to_patch_xy(tf.constant([xyz_mid], dtype=tf.float64), \n",
    "                                       patch_idx=use_patch).numpy()[0]  # (2,)\n",
    "            \n",
    "            # Model expects (batch, num_patches, 2) where batch = 1 point\n",
    "            # Stack same coords for both patches: (1, 2, 2)\n",
    "            disc_mid_both = np.stack([disc_mid, disc_mid], axis=0)[None, :, :]  # (1, 2, 2)\n",
    "            disc_mid_tf = tf.convert_to_tensor(disc_mid_both, dtype=tf.float64)\n",
    "            \n",
    "            batch_dict = {loaded_model.patch_coords_key: disc_mid_tf}\n",
    "            output = loaded_model(batch_dict, training=False)\n",
    "            # Output shape: (batch, num_patches, 2, 2) = (1, 2, 2, 2)\n",
    "            g = output[loaded_model.conformal_metric_key][0, use_patch, :, :].numpy()  # shape (2, 2)\n",
    "            \n",
    "            # Compute metric-weighted length: sqrt(direction^T @ g @ direction)\n",
    "            gv = g @ direction\n",
    "            val = direction @ gv\n",
    "            val_scalar = float(val)\n",
    "            segment_length = np.sqrt(max(val_scalar, 1e-12))\n",
    "            \n",
    "            total_length += segment_length\n",
    "        \n",
    "        return float(total_length)\n",
    "\n",
    "def build_distance_matrix(vertices_3d, faces, vertices_disc_north, vertices_disc_south,\n",
    "                          north_indices, south_indices, loaded_model, n_subdivisions=4):\n",
    "    \"\"\"Build geodesic distance matrix via shortest paths on mesh graph.\"\"\"\n",
    "    n_vertices = len(vertices_3d)\n",
    "    edges = set()\n",
    "    for face in faces:\n",
    "        for i in range(3):\n",
    "            v1, v2 = face[i], face[(i+1) % 3]\n",
    "            edges.add((min(v1, v2), max(v1, v2)))\n",
    "    print(f\"Computing {len(edges)} edge lengths...\")\n",
    "    dist_matrix = lil_matrix((n_vertices, n_vertices))\n",
    "    for idx, (i, j) in enumerate(edges):\n",
    "        if idx % 200 == 0 and idx > 0:\n",
    "            print(f\"  ...{idx}/{len(edges)}\")\n",
    "        d = compute_edge_length(i, j, vertices_3d, vertices_disc_north, vertices_disc_south,\n",
    "                                north_indices, south_indices, loaded_model, n_subdivisions)\n",
    "        dist_matrix[i, j] = d\n",
    "        dist_matrix[j, i] = d\n",
    "    print(\"Computing shortest paths...\")\n",
    "    return shortest_path(csr_matrix(dist_matrix), method='D', directed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7a51b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for MDS embedding and orientation\n",
    "\n",
    "def embed_with_mds(distance_matrix, n_components=3, max_iter=500):\n",
    "    \"\"\"Embed distance matrix into 3D using MDS.\"\"\"\n",
    "    distance_matrix = np.array(distance_matrix)\n",
    "    max_finite = np.max(distance_matrix[np.isfinite(distance_matrix)])\n",
    "    distance_matrix[~np.isfinite(distance_matrix)] = max_finite * 2\n",
    "    \n",
    "    mds = MDS(n_components=n_components, dissimilarity='precomputed', \n",
    "              random_state=42, max_iter=max_iter, normalized_stress='auto')\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        embedding = mds.fit_transform(distance_matrix)\n",
    "    print(f\"MDS stress: {mds.stress_:.4f}\")\n",
    "    return embedding\n",
    "\n",
    "def standardize_embedding_orientation(embedding):\n",
    "    \"\"\"\n",
    "    Standardize embedding orientation using first two points.\n",
    "    - Scales so average distance from origin is 1 (approximates constant volume)\n",
    "    - Rotates so first point has θ=0 (y=0, in xz-plane)\n",
    "    - Rotates so second point has φ=0 (on positive z-axis)\n",
    "    \"\"\"\n",
    "    # Get first two points\n",
    "    p1 = embedding[0].copy()\n",
    "    p2 = embedding[1].copy()\n",
    "    \n",
    "    # Scale so average distance from origin is 1 (approximates constant volume)\n",
    "    norms = np.linalg.norm(embedding, axis=1)\n",
    "    avg_norm = np.mean(norms)\n",
    "    if avg_norm > 1e-10:\n",
    "        scale_factor = 1.0 / avg_norm\n",
    "        embedding_scaled = embedding * scale_factor\n",
    "        p1 = embedding_scaled[0]\n",
    "        p2 = embedding_scaled[1]\n",
    "    else:\n",
    "        embedding_scaled = embedding.copy()\n",
    "    \n",
    "    # Rotate so first point is on positive x-axis: [1, 0, 0]\n",
    "    # Build rotation matrix that maps p1 to [1, 0, 0]\n",
    "    p1_norm = p1 / np.linalg.norm(p1)\n",
    "    target1 = np.array([1.0, 0.0, 0.0])\n",
    "    \n",
    "    # Rotation axis: cross product\n",
    "    axis = np.cross(p1_norm, target1)\n",
    "    axis_norm = np.linalg.norm(axis)\n",
    "    \n",
    "    if axis_norm > 1e-10:  # Not already aligned\n",
    "        axis = axis / axis_norm\n",
    "        # Rotation angle\n",
    "        cos_angle = np.dot(p1_norm, target1)\n",
    "        angle = np.arccos(np.clip(cos_angle, -1.0, 1.0))\n",
    "        \n",
    "        # Rodrigues rotation formula\n",
    "        K = np.array([[0, -axis[2], axis[1]],\n",
    "                      [axis[2], 0, -axis[0]],\n",
    "                      [-axis[1], axis[0], 0]])\n",
    "        R1 = np.eye(3) + np.sin(angle) * K + (1 - np.cos(angle)) * (K @ K)\n",
    "    else:\n",
    "        R1 = np.eye(3)\n",
    "    \n",
    "    embedding_rot1 = embedding_scaled @ R1.T\n",
    "    p2_rot1 = embedding_rot1[1]\n",
    "    \n",
    "    # Now rotate around x-axis so second point is in xy-plane (z=0)\n",
    "    # Second point is at some [x, y, z], we want to rotate around x-axis to make z=0\n",
    "    # Rotation around x-axis by angle theta:\n",
    "    # [1   0        0     ]\n",
    "    # [0   cos(θ)  -sin(θ)]\n",
    "    # [0   sin(θ)   cos(θ)]\n",
    "    \n",
    "    # We want z' = 0, where z' = y*sin(θ) + z*cos(θ)\n",
    "    # So: tan(θ) = -z/y\n",
    "    y2, z2 = p2_rot1[1], p2_rot1[2]\n",
    "    \n",
    "    if abs(y2) > 1e-10 or abs(z2) > 1e-10:\n",
    "        theta = np.arctan2(-z2, y2)\n",
    "        R2 = np.array([[1, 0, 0],\n",
    "                       [0, np.cos(theta), -np.sin(theta)],\n",
    "                       [0, np.sin(theta), np.cos(theta)]])\n",
    "    else:\n",
    "        R2 = np.eye(3)\n",
    "    \n",
    "    embedding_final = embedding_rot1 @ R2.T\n",
    "    \n",
    "    return embedding_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0da62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options for visualization\n",
    "save_figures = True           # Set to True to save figures to 'visualisations/' directory\n",
    "include_curvature_plots = False   # Set to True to generate 'coloured by R' plots (adds compute time)\n",
    "\n",
    "# Mesh parameters\n",
    "n_radial = 12\n",
    "n_angular = 28\n",
    "overlap_radius = 0.88\n",
    "\n",
    "# Step 1: Create unified sphere mesh\n",
    "print(\"Creating unified sphere mesh...\")\n",
    "vertices_3d, faces, vertices_disc_north, vertices_disc_south, north_indices, south_indices = \\\n",
    "    create_full_sphere_mesh(n_radial=n_radial, n_angular=n_angular, overlap_radius=overlap_radius)\n",
    "print(f\"  {len(vertices_3d)} vertices, {len(faces)} faces\")\n",
    "\n",
    "# Visualize the mesh vertices on each patch (the actual points being embedded)\n",
    "num_patches = 2 if len(vertices_disc_south) > 0 else 1\n",
    "fig, axes = plt.subplots(1, num_patches, figsize=(5*num_patches, 5))\n",
    "if num_patches == 1:\n",
    "    axes = [axes]\n",
    "axes[0].set_title('North Patch Mesh Vertices')\n",
    "axes[0].scatter(vertices_disc_north[:, 0], vertices_disc_north[:, 1], alpha=0.5, s=10)\n",
    "axes[0].set_xlim(-1, 1)\n",
    "axes[0].set_ylim(-1, 1)\n",
    "axes[0].set_aspect('equal')\n",
    "if num_patches > 1:\n",
    "    axes[1].set_title('South Patch Mesh Vertices')\n",
    "    axes[1].scatter(vertices_disc_south[:, 0], vertices_disc_south[:, 1], alpha=0.5, s=10)\n",
    "    axes[1].set_xlim(-1, 1)\n",
    "    axes[1].set_ylim(-1, 1)\n",
    "    axes[1].set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 2+: For each loaded model, compute distances, embed, and visualize\n",
    "for model_idx, loaded_model in enumerate(loaded_models):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing model: epoch {selected_models[model_idx][0]}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    # Extract config for this model\n",
    "    cfg = loaded_model.get_config()['cfg']\n",
    "\n",
    "    # Step 2: Compute geodesic distance matrix for this model\n",
    "    geodesic_distances = build_distance_matrix(\n",
    "        vertices_3d, faces, vertices_disc_north, vertices_disc_south,\n",
    "        north_indices, south_indices, loaded_model, n_subdivisions=4\n",
    ")\n",
    "\n",
    "    # Step 3: MDS embedding and orientation standardization\n",
    "    print(\"Running MDS embedding...\")\n",
    "    embedding_3d = embed_with_mds(geodesic_distances, n_components=3)\n",
    "    embedding_3d = standardize_embedding_orientation(embedding_3d)\n",
    "\n",
    "    # Step 4: Compute scalar curvature at mesh vertices (if needed)\n",
    "    if include_curvature_plots:\n",
    "        R_at_vertices = np.zeros(len(vertices_3d))\n",
    "        # For each patch, predict R using the model\n",
    "        # Model expects (batch, num_patches, 2) where batch = N points\n",
    "        # Stack same coords for both patches: (N, 2, 2)\n",
    "        vertices_north_both = np.stack([vertices_disc_north, vertices_disc_north], axis=1)\n",
    "        vertices_tf_north = tf.convert_to_tensor(vertices_north_both, dtype=tf.float64)\n",
    "        batch_dict_north = {loaded_model.patch_coords_key: vertices_tf_north}\n",
    "        output_north = loaded_model(batch_dict_north, training=False)\n",
    "        # Output shape: (N, 2, ...)\n",
    "        u_north = output_north[loaded_model.conformal_factor_key][:, 0].numpy().squeeze()\n",
    "        delta_u_north = output_north[loaded_model.laplace_beltrami_key][:, 0].numpy().squeeze()\n",
    "        R_north = np.exp(-2.0 * u_north) * (2.0 - delta_u_north)\n",
    "        R_at_vertices[north_indices] = R_north\n",
    "        if num_patches > 1:\n",
    "            vertices_south_both = np.stack([vertices_disc_south, vertices_disc_south], axis=1)\n",
    "            vertices_tf_south = tf.convert_to_tensor(vertices_south_both, dtype=tf.float64)\n",
    "            batch_dict_south = {loaded_model.patch_coords_key: vertices_tf_south}\n",
    "            output_south = loaded_model(batch_dict_south, training=False)\n",
    "            u_south = output_south[loaded_model.conformal_factor_key][:, 1].numpy().squeeze()\n",
    "            delta_u_south = output_south[loaded_model.laplace_beltrami_key][:, 1].numpy().squeeze()\n",
    "            R_south = np.exp(-2.0 * u_south) * (2.0 - delta_u_south)\n",
    "            R_at_vertices[south_indices] = R_south\n",
    "\n",
    "    # Step 5: Setup visualization parameters\n",
    "    R_kind = cfg['data'].get('prescribed_R', 'unknown')\n",
    "    title_suffix = f\"R_kind={R_kind}, epoch={selected_models[model_idx][0]}\"\n",
    "\n",
    "    # Step 6: Plot learned metric embedding\n",
    "    fig = plt.figure(figsize=(8, 7))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_trisurf(embedding_3d[:, 0], embedding_3d[:, 1], embedding_3d[:, 2],\n",
    "                     triangles=faces, cmap='viridis', alpha=0.7, edgecolor='k', linewidth=0.15)\n",
    "    #ax.set_title(f'Learned Metric Embedding\\n({title_suffix})')\n",
    "    ax.set_xlabel('X'); ax.set_ylabel('Y'); ax.set_zlabel('Z')\n",
    "    ax.set_box_aspect([1,1,1])\n",
    "    plt.tight_layout()\n",
    "    if save_figures:\n",
    "        save_dir = os.path.join(\"visualisations\", selected_folder)\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        fig.savefig(os.path.join(save_dir, f\"embedding_epoch_{selected_models[model_idx][0]}_K_{R_kind}.pdf\"), bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d06919",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Create animation from all epochs\n",
    "import imageio.v2 as imageio\n",
    "from io import BytesIO\n",
    "\n",
    "# Ensure model_epochs is defined as the list of epochs for loaded_models\n",
    "model_epochs = [e for e, _ in selected_models]\n",
    "\n",
    "def create_embedding_animation(output_filename='metric_evolution_embedding.gif', fps=2):\n",
    "    \"\"\"\n",
    "    Create animated GIF showing metric embedding evolution across epochs.\n",
    "    \n",
    "    Args:\n",
    "        output_filename: Output file path (supports .gif, .mp4)\n",
    "        fps: Frames per second\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    \n",
    "    # First pass: determine global axis limits across all embeddings\n",
    "    print(\"Computing global axis limits...\")\n",
    "    all_embeddings = []\n",
    "    \n",
    "    for model_idx, (loaded_model, epoch_label) in enumerate(zip(loaded_models, model_epochs)):\n",
    "        print(f\"  Processing epoch {epoch_label} for limits...\")\n",
    "        geodesic_distances = build_distance_matrix(\n",
    "            vertices_3d, faces, vertices_disc_north, vertices_disc_south,\n",
    "            north_indices, south_indices, loaded_model, n_subdivisions=4\n",
    "        )\n",
    "        embedding_3d = embed_with_mds(geodesic_distances, n_components=3)\n",
    "        embedding_3d = standardize_embedding_orientation(embedding_3d)\n",
    "        all_embeddings.append(embedding_3d)\n",
    "    \n",
    "    # Compute global limits\n",
    "    all_embeddings_array = np.vstack(all_embeddings)\n",
    "    x_min, x_max = all_embeddings_array[:, 0].min(), all_embeddings_array[:, 0].max()\n",
    "    y_min, y_max = all_embeddings_array[:, 1].min(), all_embeddings_array[:, 1].max()\n",
    "    z_min, z_max = all_embeddings_array[:, 2].min(), all_embeddings_array[:, 2].max()\n",
    "    \n",
    "    # Add 5% padding\n",
    "    x_range = x_max - x_min\n",
    "    y_range = y_max - y_min\n",
    "    z_range = z_max - z_min\n",
    "    padding = 0.05\n",
    "    \n",
    "    x_min -= x_range * padding\n",
    "    x_max += x_range * padding\n",
    "    y_min -= y_range * padding\n",
    "    y_max += y_range * padding\n",
    "    z_min -= z_range * padding\n",
    "    z_max += z_range * padding\n",
    "    \n",
    "    print(f\"\\nGlobal axis limits:\")\n",
    "    print(f\"  X: [{x_min:.3f}, {x_max:.3f}]\")\n",
    "    print(f\"  Y: [{y_min:.3f}, {y_max:.3f}]\")\n",
    "    print(f\"  Z: [{z_min:.3f}, {z_max:.3f}]\")\n",
    "    \n",
    "    # Second pass: create animation frames\n",
    "    print(\"\\nRendering animation frames...\")\n",
    "    for model_idx, (loaded_model, epoch_label) in enumerate(zip(loaded_models, model_epochs)):\n",
    "        print(f\"  Frame {model_idx+1}/{len(loaded_models)}: epoch {epoch_label}\")\n",
    "        \n",
    "        embedding_3d = all_embeddings[model_idx]\n",
    "        \n",
    "        # Setup title\n",
    "        try:\n",
    "            model_cfg = loaded_model.get_config()['cfg']\n",
    "            R_kind = model_cfg['data'].get('prescribed_R', 'unknown')\n",
    "        except Exception:\n",
    "            R_kind = 'unknown'\n",
    "        \n",
    "        if R_kind == \"sph_harm\":\n",
    "            ms_values = getattr(loaded_model, 'hp', {}).get(\"ms\", []) if hasattr(loaded_model, 'hp') else []\n",
    "            title_suffix = f\"R_kind={R_kind}, ms={ms_values}\"\n",
    "        else:\n",
    "            title_suffix = f\"R_kind={R_kind}\"\n",
    "        \n",
    "        if epoch_label != \"seed\":\n",
    "            title_suffix = f\"Epoch {epoch_label}, {title_suffix}\"\n",
    "        \n",
    "        # Create figure\n",
    "        fig = plt.figure(figsize=(8, 7), dpi=100)\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        \n",
    "        ax.plot_trisurf(embedding_3d[:, 0], embedding_3d[:, 1], embedding_3d[:, 2],\n",
    "                      triangles=faces, cmap='viridis', alpha=0.7, edgecolor='k', linewidth=0.15)\n",
    "        ax.set_title(f'Learned Metric Embedding\\n({title_suffix})')\n",
    "        \n",
    "        ax.set_xlabel('X'); ax.set_ylabel('Y'); ax.set_zlabel('Z')\n",
    "        \n",
    "        # Set consistent axis limits and view angle for all frames\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        ax.set_zlim(z_min, z_max)\n",
    "        ax.set_box_aspect([x_range, y_range, z_range])\n",
    "        ax.view_init(elev=20, azim=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Convert to image\n",
    "        buf = BytesIO()\n",
    "        plt.savefig(buf, format='png', dpi=100)\n",
    "        buf.seek(0)\n",
    "        frames.append(imageio.imread(buf))\n",
    "        plt.close(fig)\n",
    "    \n",
    "    # Save animation\n",
    "    if save_figures:\n",
    "        save_dir = os.path.join(\"visualisations\", selected_folder)\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        output_path = os.path.join(save_dir, output_filename)\n",
    "    else:\n",
    "        output_path = output_filename\n",
    "    \n",
    "    imageio.mimsave(output_path, frames, fps=fps, loop=0)\n",
    "    print(f\"\\nAnimation saved to: {output_path}\")\n",
    "    print(f\"Total frames: {len(frames)}, Duration: {len(frames)/fps:.1f}s\")\n",
    "\n",
    "# Create embedding animation\n",
    "create_embedding_animation('metric_evolution_embedding.gif', fps=2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b05c731",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Plot Reference Round Sphere Only\n",
    "# Run this cell after running the embedding cell above to plot the reference sphere separately.\n",
    "save_reference_figures = False  # Set to True to save figures\n",
    "\n",
    "# Reference sphere plots always save to visualisations/ directly (not a subfolder)\n",
    "if save_reference_figures:\n",
    "    save_dir = \"visualisations\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Plot 1: Reference sphere mesh\n",
    "fig = plt.figure(figsize=(8, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_trisurf(vertices_3d[:, 0], vertices_3d[:, 1], vertices_3d[:, 2],\n",
    "                triangles=faces, cmap='Blues', alpha=0.7, edgecolor='k', linewidth=0.15)\n",
    "ax.set_title('Reference Sphere (Round Metric)')\n",
    "ax.set_xlabel('X'); ax.set_ylabel('Y'); ax.set_zlabel('Z')\n",
    "ax.set_box_aspect([1,1,1])\n",
    "plt.tight_layout()\n",
    "if save_reference_figures:\n",
    "    fig.savefig(os.path.join(save_dir, \"reference_sphere.pdf\"), bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Reference sphere coloured by learned R (only if curvature plots enabled)\n",
    "if include_curvature_plots:\n",
    "    fig2 = plt.figure(figsize=(8, 7))\n",
    "    ax = fig2.add_subplot(111, projection='3d')\n",
    "    sc = ax.scatter(vertices_3d[:, 0], vertices_3d[:, 1], vertices_3d[:, 2],\n",
    "                    c=R_at_vertices, cmap='coolwarm', s=30, edgecolor='k', linewidth=0.1)\n",
    "    ax.plot_trisurf(vertices_3d[:, 0], vertices_3d[:, 1], vertices_3d[:, 2],\n",
    "                    triangles=faces, alpha=0.3, color='gray', edgecolor='none')\n",
    "    ax.set_title('Round Sphere '\n",
    "    '(coloured by R)')\n",
    "    ax.set_xlabel('X'); ax.set_ylabel('Y'); ax.set_zlabel('Z')\n",
    "    ax.set_box_aspect([1,1,1])\n",
    "    plt.colorbar(sc, ax=ax, shrink=0.5, label='Scalar Curvature R')\n",
    "    plt.tight_layout()\n",
    "    if save_reference_figures:\n",
    "        fig2.savefig(os.path.join(save_dir, \"reference_sphere_curvature.pdf\"), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e53a0d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
